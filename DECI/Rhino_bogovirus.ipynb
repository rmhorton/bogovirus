{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep End-to-end Causal Inference: Demo Notebook\n",
        "\n",
        "This notebook provides a showcase of the features provided by our open source code for Deep End-to-end Causal Inference (DECI).\n",
        "\n",
        " - We begin with a simple two node example, showing how DECI can orient an edge correctly when non-Gaussian noise is present, and how DECI can then be used for treatment effect estimation\n",
        " - We show how different graph constraints can be incorporated into DECI\n",
        " - We showcase DECI on a larger graph example\n",
        "\n",
        "## Notebook Setup\n",
        "\n",
        "### Setup on AML\n",
        "You can setup AML environment for causica by running the following commands on the terminal. Then, before running the notebook make sure you selected \"causica\" as your environment on top-right.\n",
        "\n",
        "    conda create -n \"causica\" python==3.9 ipython\n",
        "    conda activate causica\n",
        "    conda install -y pip\n",
        "    conda install -y ipykernel\n",
        "    python -m ipykernel install --user --name causica --display-name causica\n",
        "    sudo apt install graphviz-dev\n",
        "    pip install git+https://github.com/microsoft/causica@9826ee9ba7dd63d72aaa0b3e0fd09636e38dd5bc\n",
        "    pip install azureml-mlflow==1.46.0\n",
        "\n",
        "<!-- pip install -r requirements.txt -->"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "e759c296-f7ac-4d6a-b6b6-b145e9368111",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup on Databricks\n",
        "Uncomment the following cell that will init-script on dbfs; set it up on your cluster. \n",
        "You can find more info on how to do so in this [link](https://learn.microsoft.com/en-us/azure/databricks/clusters/init-scripts#configure-a-cluster-scoped-init-script)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "8ee7ffd6-5215-41bd-a757-78d8695a10a6",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %python\n",
        "# dbutils.fs.put(\n",
        "#     \"dbfs:/databricks/init_scripts/install-pygraphviz-causica.sh\",\n",
        "#     \"\"\"\n",
        "#     #!/bin/bash\n",
        "#     #install dependent packages\n",
        "#     sudo apt-get install -y python3-dev graphviz libgraphviz-dev pkg-config\n",
        "#     pip install pygraphviz\n",
        "#     pip install git+https://github.com/microsoft/causica@9826ee9ba7dd63d72aaa0b3e0fd09636e38dd5bc\"\"\", True)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "32631ee6-5b05-4da9-8c30-69f1200f3290",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679322084880
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "dbbfd2d1-81e4-45dd-81e0-9561ca9c83e2",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\r\n",
        "sys.path.append(\"../..\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322086359
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from causica_pkg.causica.models.deci.rhino import Rhino\r\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322091984
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some imports to get us started\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore::FutureWarning'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# Utilities\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Causica imports\n",
        "# from causica_pkg.causica.models.deci.deci import DECI\n",
        "from causica_pkg.causica.datasets.dataset import Dataset\n",
        "from causica_pkg.causica.datasets.variables import Variables\n",
        "from causica_pkg.causica.experiment.steps.step_func import load_data\n",
        "\n",
        "# Plots\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# device: change cuda to cpu if GPU is not available; we recommend gpu training\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "8e6399f0-8f0c-4eca-ad39-090149c53861",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679322093279
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "We read the data from BogoVirus with random dose policy. We then convert the data in a format containing information of prev. and cur. days. Patients are sampled into train-test files. All the records of the the patients in trainset is used to train DECI model. The test set is used for validation of ATE estimations, which is not covered in this notebook.\n",
        "\n",
        "The dataset is simulated before and here we only load it from SQL:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "1f5bc334-90f4-437d-b099-26b6e47ac3de",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "df = pd.read_csv(\"../../data/bogo/cnt_100_patients.csv\")\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "   patient_id  cohort  day_number  infection   severity  drug  cum_drug  \\\n0        9018      10           1         30  18.672222   0.2  0.061564   \n1        9018      10           2         37  23.850061   0.5  0.186697   \n2        9018      10           3         40  24.831434   0.0  0.128113   \n3        9018      10           4         46  31.784742   0.5  0.238457   \n4        9018      10           5         52  33.240071   0.5  0.313421   \n\n   efficacy outcome  reward  \n0  2.254764     NaN      -1  \n1  5.611975     NaN      -1  \n2  0.154652     NaN      -1  \n3  5.773507     NaN      -1  \n4  5.461095     NaN      -1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>cohort</th>\n      <th>day_number</th>\n      <th>infection</th>\n      <th>severity</th>\n      <th>drug</th>\n      <th>cum_drug</th>\n      <th>efficacy</th>\n      <th>outcome</th>\n      <th>reward</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9018</td>\n      <td>10</td>\n      <td>1</td>\n      <td>30</td>\n      <td>18.672222</td>\n      <td>0.2</td>\n      <td>0.061564</td>\n      <td>2.254764</td>\n      <td>NaN</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9018</td>\n      <td>10</td>\n      <td>2</td>\n      <td>37</td>\n      <td>23.850061</td>\n      <td>0.5</td>\n      <td>0.186697</td>\n      <td>5.611975</td>\n      <td>NaN</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9018</td>\n      <td>10</td>\n      <td>3</td>\n      <td>40</td>\n      <td>24.831434</td>\n      <td>0.0</td>\n      <td>0.128113</td>\n      <td>0.154652</td>\n      <td>NaN</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9018</td>\n      <td>10</td>\n      <td>4</td>\n      <td>46</td>\n      <td>31.784742</td>\n      <td>0.5</td>\n      <td>0.238457</td>\n      <td>5.773507</td>\n      <td>NaN</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9018</td>\n      <td>10</td>\n      <td>5</td>\n      <td>52</td>\n      <td>33.240071</td>\n      <td>0.5</td>\n      <td>0.313421</td>\n      <td>5.461095</td>\n      <td>NaN</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322094164
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"outcome\"]=df[\"outcome\"].fillna(\"stay\")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322094803
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_rhino = df.sort_values(by=[\"patient_id\", \"day_number\"]).loc[:,\r\n",
        "    [\"patient_id\", \"infection\", \"severity\", \"drug\", \"cum_drug\", \"efficacy\", \"outcome\"]\r\n",
        "]\r\n",
        "\r\n",
        "df_rhino.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "    patient_id  infection   severity  drug  cum_drug  efficacy outcome\n89         495         37  18.332330   0.1  0.028877  0.618856    stay\n90         495         41  23.319683   0.2  0.080129  2.530860    stay\n91         495         44  27.401423   0.4  0.176783  4.378567    stay\n92         495         44  29.735350   0.5  0.277358  6.129380    stay\n93         495         53  30.711535   0.5  0.339562  5.858048    stay",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>infection</th>\n      <th>severity</th>\n      <th>drug</th>\n      <th>cum_drug</th>\n      <th>efficacy</th>\n      <th>outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>89</th>\n      <td>495</td>\n      <td>37</td>\n      <td>18.332330</td>\n      <td>0.1</td>\n      <td>0.028877</td>\n      <td>0.618856</td>\n      <td>stay</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>495</td>\n      <td>41</td>\n      <td>23.319683</td>\n      <td>0.2</td>\n      <td>0.080129</td>\n      <td>2.530860</td>\n      <td>stay</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>495</td>\n      <td>44</td>\n      <td>27.401423</td>\n      <td>0.4</td>\n      <td>0.176783</td>\n      <td>4.378567</td>\n      <td>stay</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>495</td>\n      <td>44</td>\n      <td>29.735350</td>\n      <td>0.5</td>\n      <td>0.277358</td>\n      <td>6.129380</td>\n      <td>stay</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>495</td>\n      <td>53</td>\n      <td>30.711535</td>\n      <td>0.5</td>\n      <td>0.339562</td>\n      <td>5.858048</td>\n      <td>stay</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322095592
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_rhino.to_csv(\"../../data/bogo/all.csv\", index=False)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322096859
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_config = {\r\n",
        "    \"dataset_format\": \"temporal_causal_csv\",\r\n",
        "    \"timeseries_column_index\": 0,\r\n",
        "    \"use_predefined_dataset\": False,\r\n",
        "    \"random_seed\": [0],\r\n",
        "    \"negative_sample\": False\r\n",
        "}\r\n",
        "\r\n",
        "# DECI configurations\r\n",
        "model_hyperparams={\r\n",
        "  \"ICGNN_embedding_size\": None,\r\n",
        "  \"additional_spline_flow\": 0,\r\n",
        "  \"allow_instantaneous\": False,\r\n",
        "  \"base_distribution_type\": \"gaussian\",\r\n",
        "  \"cate_rff_lengthscale\": [\r\n",
        "    0.1,\r\n",
        "    1\r\n",
        "  ],\r\n",
        "  \"cate_rff_n_features\": 3000,\r\n",
        "  \"conditional_decoder_layer_sizes\": [\r\n",
        "    10\r\n",
        "  ],\r\n",
        "  \"conditional_embedding_size\": 16,\r\n",
        "  \"conditional_encoder_layer_sizes\": [\r\n",
        "    10\r\n",
        "  ],\r\n",
        "  \"conditional_spline_order\": \"linear\",\r\n",
        "  \"decoder_layer_sizes\": [\r\n",
        "    10\r\n",
        "  ],\r\n",
        "  \"encoder_layer_sizes\": [\r\n",
        "    10\r\n",
        "  ],\r\n",
        "  \"imputation\": False,\r\n",
        "  \"init_logits\": [\r\n",
        "    -3,\r\n",
        "    -3\r\n",
        "  ],\r\n",
        "  \"lag\": 2,\r\n",
        "  \"lambda_dag\": 10,\r\n",
        "  \"lambda_prior\": 100000,\r\n",
        "  \"lambda_sparse\": 15,\r\n",
        "  \"norm_layers\": True,\r\n",
        "  \"prior_A_confidence\": 0.5,\r\n",
        "  \"random_seed\": 0,\r\n",
        "  \"res_connection\": True,\r\n",
        "  \"spline_bins\": 8,\r\n",
        "  \"tau_gumbel\": 0.25,\r\n",
        "  \"var_dist_A_mode\": \"temporal_three\"\r\n",
        "}\r\n",
        "training_hyperparams={\r\n",
        "    \"learning_rate\": 0.001,\r\n",
        "    \"likelihoods_learning_rate\": 0.001,\r\n",
        "    \"batch_size\": 64,\r\n",
        "    \"stardardize_data_mean\": False,\r\n",
        "    \"stardardize_data_std\": False,\r\n",
        "    \"rho\": 1.0,\r\n",
        "    \"safety_rho\": 10000000000000.0,\r\n",
        "    \"alpha\": 0.0,\r\n",
        "    \"safety_alpha\": 10000000000000.0,\r\n",
        "    \"tol_dag\": -1,\r\n",
        "    \"progress_rate\": 0.65,\r\n",
        "    \"max_steps_auglag\": 60,\r\n",
        "    \"max_auglag_inner_epochs\": 6000,\r\n",
        "    \"max_p_train_dropout\": 0,\r\n",
        "    \"reconstruction_loss_factor\": 1.0,\r\n",
        "    \"anneal_entropy\": \"noanneal\"\r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322151044
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create variables & Dataset objects"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method for creating variables.json\r\n",
        "def create_variables(df, categorical_vars={}, timeseries_column_index=0, variables_json_path=None, text_vars=None, target_column_names=[]):\r\n",
        "    if text_vars is None:\r\n",
        "        text_vars = []\r\n",
        "    variables_info = []\r\n",
        "\r\n",
        "    for ident, column_name in enumerate(df.columns):\r\n",
        "        # if ident == timeseries_column_index:\r\n",
        "        # continue\r\n",
        "        query = column_name if target_column_names is not None else ident != len(df.columns) - 1\r\n",
        "        var = {\r\n",
        "            \"id\": ident,\r\n",
        "            \"query\": query,\r\n",
        "            \"name\": column_name,\r\n",
        "        }\r\n",
        "        if column_name not in text_vars:\r\n",
        "            var[\"type\"] = \"categorical\" if column_name in categorical_vars else \"continuous\"\r\n",
        "            var[\"lower\"] = 0 if column_name in categorical_vars else np.nanmin(df[column_name])\r\n",
        "            var[\"upper\"] = (\r\n",
        "                categorical_vars[column_name] - 1 if column_name in categorical_vars else np.nanmax(df[column_name])\r\n",
        "            )\r\n",
        "        elif column_name in text_vars:\r\n",
        "            var[\"type\"] = \"text\"\r\n",
        "            var[\"overwrite_processed_dim\"] = 768  # Sentence Transformer model has that dimension\r\n",
        "\r\n",
        "        if column_name in target_column_names:\r\n",
        "            var[\"group_name\"]=\"targets\"\r\n",
        "        variables_info.append(var)\r\n",
        "\r\n",
        "    variable_dict = {\"variables\": variables_info, \"metadata_variables\": []}\r\n",
        "    del variable_dict[\"variables\"][timeseries_column_index]\r\n",
        "    variables = Variables.create_from_dict(variable_dict)\r\n",
        "    if variables_json_path:\r\n",
        "        variables.save(variables_json_path)\r\n",
        "    return variables"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322153646
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from causica_pkg.causica.experiment.run_context import RunContext\r\n",
        "run_context = RunContext()"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322155993
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from causica_pkg.causica.datasets.dataset import Dataset\r\n",
        "from causica_pkg.causica.datasets.variables import Variables\r\n",
        "\r\n",
        "# Set up data in a suitable form for DECI to consume, using the loaded data types\r\n",
        "mask_data = ~df_rhino.isna()\r\n",
        "data_mask = mask_data.to_numpy().astype(int) # np.ones(numpy_data.shape)\r\n",
        "\r\n",
        "# na to zero\r\n",
        "df_rhino=df_rhino.fillna(0)\r\n",
        "numpy_data = df_rhino.to_numpy()"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679321943748
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "array([[495, 37, 18.332329910196396, ..., 0.0288769015219383,\n        0.6188559705515274, 'stay'],\n       [495, 41, 23.319682971669756, ..., 0.0801294139741463,\n        2.5308602568804144, 'stay'],\n       [495, 44, 27.40142312571836, ..., 0.1767826080763779,\n        4.378566919844883, 'stay'],\n       ...,\n       [98807, 83, 88.53074293036846, ..., 0.6942986198902211,\n        4.65661614782621, 'stay'],\n       [98807, 84, 99.89051714011596, ..., 0.8490488597814572,\n        0.6065761843540785, 'stay'],\n       [98807, 91, 118.86438978782888, ..., 1.3481529949986648,\n        0.117537098830667, 'die']], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322019464
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no missingness\r\n",
        "pd.isna(numpy_data).sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679321944733
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_mask.sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "9695"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679321945848
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_mask.shape[0] * data_mask.shape[1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "9695"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679321947371
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables = create_variables(df, categorical_vars={\"outcome\":3}, timeseries_column_index=0)\r\n",
        "dataset = Dataset(train_data=numpy_data, train_mask=np.ones(numpy_data.shape), variables=variables)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679321948364
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we create a directory to save the results of all the experiments\r\n",
        "outputs_root = \"../../runs/\"\r\n",
        "os.makedirs(outputs_root, exist_ok=True)\r\n",
        "\r\n",
        "model_id = f\"bogo_{datetime.now():%Y_%m_%d_%H%M%S}\"\r\n",
        "model = Rhino.create(model_id, save_dir=os.path.join(outputs_root, model_id), variables=variables, model_config_dict=model_hyperparams, device=device)\r\n",
        "# model.set_graph_constraint(constraint_matrix)\r\n",
        "model.run_train(dataset, training_hyperparams)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m Rhino\u001b[38;5;241m.\u001b[39mcreate(model_id, save_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(outputs_root, model_id), variables\u001b[38;5;241m=\u001b[39mvariables, model_config_dict\u001b[38;5;241m=\u001b[39mmodel_hyperparams, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# model.set_graph_constraint(constraint_matrix)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39mrun_train(dataset, training_hyperparams)\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/matavako1-causica-cpu/code/Users/matavako/bogovirus/causica_pkg/causica/models/deci/rhino.py:988\u001b[0m, in \u001b[0;36mRhino.run_train\u001b[0;34m(self, dataset, train_config_dict, report_progress_callback)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;124;03mThis method implements the training scripts of AR-DECI. This also setup a soft prior (if exists) for the AR-DECI.\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03mWe should also change the termination condition rather than the using num_below_tol in DECI,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;124;03mReturns: No return\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# Load the soft prior from dataset if exists and update the prior for AR-DECI by calling self.set_prior_A(...).\u001b[39;00m\n\u001b[0;32m--> 988\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, TemporalDataset)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# Setup the logging machinery (similar to DECI training).\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# Setup the optimizer (similar to DECI training).\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# Outer optimization loop. Note the termination condition should be changed based on the value we set for allow_instantaneous.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# Inner loop by calling self.optimize_inner_auglag(...). No change is needed.\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# Update rho, alpha, loss tracker (similar to DECI).\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m train_config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_p_train_dropout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent AR-DECI does not support missing values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679322309984
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_variables_json(df, categorical_vars, variables_json_path, text_vars=None, target_column_names=None):\n",
        "#     \"\"\"\n",
        "#     The method returns Variables object (causica.datasets.variables.Variables), and also saves the json file; \n",
        "#     The saved json file is for potential future use and the returned object is sufficient for what causica expects. \n",
        "\n",
        "#     df <pandas.DataFrame> dataset that variable types and boundries will be extracted from\n",
        "#     categorical_vars <dict> a dictionary of categorical variables & the number of categories for each. e.g., {\"gender\":2, \"race\": 6}.\n",
        "#     variables_json_path <str> filepath to save the variables dictionary\n",
        "\n",
        "#     returns <causica.datasets.variables.Variables> variables\n",
        "#     \"\"\"\n",
        "#     if text_vars is None:\n",
        "#         text_vars = []\n",
        "#     variables_info = []\n",
        "\n",
        "#     for ident, column_name in enumerate(df.columns):\n",
        "#         query = True if target_column_names is None else column_name not in target_column_names \n",
        "#         var = {\n",
        "#             \"id\": ident,\n",
        "#             \"query\": query,\n",
        "#             \"name\": column_name,\n",
        "#         }\n",
        "#         if column_name not in text_vars:\n",
        "#             var[\"type\"] = \"categorical\" if column_name in categorical_vars else \"continuous\"\n",
        "#             var[\"type\"] = \"binary\" if (var[\"type\"]==\"categorical\" and categorical_vars[column_name]==2) else var[\"type\"]\n",
        "#             var[\"lower\"] = 0 if column_name in categorical_vars else np.nanmin(df[column_name])\n",
        "#             var[\"upper\"] = (\n",
        "#                 categorical_vars[column_name] - 1 if column_name in categorical_vars else np.nanmax(df[column_name])\n",
        "#             )\n",
        "#         elif column_name in text_vars:\n",
        "#             var[\"type\"] = \"text\"\n",
        "#             var[\"overwrite_processed_dim\"] = 768  # Sentence Transformer model has that dimension\n",
        "\n",
        "#         if target_column_names and column_name in target_column_names:\n",
        "#             var[\"group_name\"]=\"targets\"\n",
        "#         variables_info.append(var)\n",
        "#     variables = Variables.create_from_dict({\"variables\": variables_info, \"metadata_variables\": []})\n",
        "#     variables.save(variables_json_path)\n",
        "#     return variables"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "853382c2-0532-4d4b-ac73-3abb42af2102",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679321950875
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # This data pre-processing treat all variables as continuous, although some of them are ordinal --  categorical_vars={'status':3}\n",
        "# variables_json_path=data_dir + 'bogo_time/variables.json'\n",
        "# os.makedirs(data_dir + 'bogo_time', exist_ok=True)\n",
        "\n",
        "# # create variables object\n",
        "# variables = create_variables_json(df_all, categorical_vars={'die':2, 'recover':2,'prev1_die':2, 'prev1_recover':2}, variables_json_path=variables_json_path, text_vars=None, target_column_names=[])\n",
        "# varindex_to_name = {i: var.name for (i, var) in enumerate(variables)}\n",
        "# varname_to_index = {var.name:i for (i, var) in enumerate(variables)}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "a203b069-ea4b-437e-85cd-0b9a28ed4423",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679321950925
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset object"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "6dc2e006-9af0-4c36-b4f8-ae707c9fd155",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_dataset_obj(df_input, variables):\n",
        "#   # Set up data in a suitable form for DECI to consume, using the loaded data types\n",
        "#   # data_mask = ~df_input.isna().to_numpy() # np.ones(numpy_data.shape)\n",
        "#   data_mask = ~np.isnan(df_input.to_numpy()) # deci can tolerate missing data; this mask help DECI distinguish \n",
        "\n",
        "#   # na to zero\n",
        "#   numpy_data=df_input.fillna(0).to_numpy()\n",
        "#   # print(numpy_data)\n",
        "#   dataset = Dataset(train_data=numpy_data, train_mask=data_mask, variables=variables)\n",
        "#   return dataset\n",
        "\n",
        "# # create dataset object for train-data\n",
        "# train_dataset = create_dataset_obj(df_train_cohort, variables)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "5d996746-5237-4c4c-bc23-985f1c4ce7fc",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679321950977
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train_cohort.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "94b2968b-2f72-47ee-8707-c84216831c65",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679321951045
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Graph Discovery\n",
        "\n",
        "The following snippets step through the process of:\n",
        " - configuring and creating a DECI model\n",
        " - training a model with no graph constraints\n",
        " - training a model with graph constraints\n",
        " \n",
        "*Note*: if you have already trained a DECI model, you can reload the model by skipping to the section below on \"Loading a saved DECI model\""
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "50359ca4-55e5-4a68-8899-83aaa4988bb9",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # we create a directory to save the results of all the experiments\n",
        "# outputs_root = \"bogovirus/runs/\"\n",
        "# os.makedirs(outputs_root, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "45500630-c8d9-41de-a41c-e3948e8d4ad4",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269447
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device = \"0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "f665238e-7611-4c83-ac4c-e3518aa0e64e",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269479
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Train with No Constraint\n",
        "\n",
        "#### **Note** -- DECI configuration\n",
        "\n",
        "The DECI model has a number of hyperparameters, but attention need not be paid to all of them. Here we highlight key hyperparameters that might be changed to improve performance:\n",
        " - `learning_rate` is the step size for the Adam optimizer. Decrease the learning rate if training is unstable\n",
        " - `var_dist_A_learning_rate` is the learning rate for the causal graph distribution\n",
        " - `standardize_data_mean` and `standardize_data_std` tell DECI to standarize the data by subtracting the mean and dividing by the standard deviation of each column. *Note*: this improves training, but you need to take care because treatment effects will now be computed in this standardized space\n",
        " - `max_auglag_inner_epochs` is the number of gradient steps taken in each \"inner step\" of the DECI optimization. Decrease this to speed up training (at the risk of training not converging). Increase this to learn a more accurate model, or when the dataset is larger.\n",
        " - `max_steps_auglag` is the maximum number of \"inner steps\" taken. Decrease this to end training early (e.g. before a DAG has been found) to speed up training\n",
        " - `base_distribution_type` is the type of DECI model that is trained. It should be either `gaussian` or `spline`. Use `spline` for highly non-Gaussian data, or to fit a better density model of the observational data.\n",
        " - `lambda_sparse` controls the coefficient of graph sparsity regularizer.\n",
        " \n",
        "Other hyperparameters are less frequently changed.\n",
        "\n",
        "\n",
        "To speed up training you can try the followings:\n",
        " - increasing `learning_rate`\n",
        " - increasing `batch_size` (reduces noise when using higher learning rate)\n",
        " - decreasing `max_steps_auglag` (go as low as you can and still get a DAG)\n",
        " - decreasing `max_auglag_inner_epochs`\n",
        "\n",
        "Note that an undertrained model might be unsuccessful to converge to a DAG or may have less accurate predictions."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "8c65f400-17e9-4158-afb5-2dfc975d7d8c",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # DECI configurations\n",
        "# model_config = {\n",
        "#     \"tau_gumbel\": 0.25,\n",
        "#     \"lambda_dag\": 200.0,\n",
        "#     \"lambda_sparse\": 5.0,\n",
        "#     \"lambda_prior\": 0.0,\n",
        "#     # Choosing a Gaussian DECI model, alternative is \"spline\"/\"gaussian\"\n",
        "#     \"base_distribution_type\": \"spline\",\n",
        "#     \"imputation\": False,\n",
        "#     \"spline_bins\": 8,\n",
        "#     \"var_dist_A_mode\": \"enco\",\n",
        "#     \"mode_adjacency\": \"learn\",\n",
        "#     # ?\n",
        "#     'norm_layers': True, \n",
        "#     'res_connection': True,\n",
        "# }\n",
        "\n",
        "# training_params = {\n",
        "#     # Setting higher learning rates can speed up training, but risks some instability\n",
        "#     \"learning_rate\": 1e-3,\n",
        "#     \"var_dist_A_learning_rate\": 1e-2,\n",
        "#     \"batch_size\": 512, #256,\n",
        "#     # This standarizes the data before training. The DECI model operates in standardized space.\n",
        "#     \"standardize_data_mean\": False, #True,\n",
        "#     \"standardize_data_std\": False, #True,\n",
        "#     \"rho\": 1.0,\n",
        "#     \"safety_rho\": 1e18,\n",
        "#     \"alpha\": 0.0,\n",
        "#     \"safety_alpha\": 1e18,\n",
        "#     \"tol_dag\": 1e-9,\n",
        "#     \"progress_rate\": 0.65,\n",
        "#     # We are setting this large to wait until we find a DAG\n",
        "#     \"max_steps_auglag\": 50,\n",
        "#     # We are setting this large to learn a more accurate model.\n",
        "#     \"max_auglag_inner_epochs\": 2000,\n",
        "#     \"max_p_train_dropout\": 0.2,\n",
        "#     \"reconstruction_loss_factor\": 1.0,\n",
        "#     \"anneal_entropy\": \"noanneal\",\n",
        "# }"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "9bd1b945-0659-4bbe-b4ef-388892b5fcc1",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269509
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_cohort.head(2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "ca88fd1b-fea5-4c2e-bb89-66fcb558c5ee",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269542
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_id = f\"bogo_{datetime.now():%Y_%m_%d_%H%M%S}\"\n",
        "# model = DECI.create(model_id, save_dir=os.path.join(outputs_root, model_id), variables=variables, model_config_dict=model_config, device=device)\n",
        "# # model.set_graph_constraint(constraint_matrix)\n",
        "# model.run_train(train_dataset, training_params)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "35745923-2eac-4d8f-bb3f-d0072b7fca19",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269576
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Saved as \", model_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "66fe9a70-4e77-41bb-ac60-5e5fbceb4735",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269609
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_id=\"bogo_2022_11_03_013822\"\n",
        "# # model = DECI.load(model_id, os.path.join(outputs_root, model_id), device=device)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "c72db778-85d5-4ffd-bbf8-668a53fa943b",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269641
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_graph = model.networkx_graph()\n",
        "# pred_graph = nx.relabel_nodes(pred_graph, varindex_to_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "f67feeed-9c6c-4975-952a-34301b972063",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269673
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def topological_plot(G):\n",
        "#     # G is a nx.DiGraph object\n",
        "#     for layer, nodes in enumerate(nx.topological_generations(G)):\n",
        "#         # `multipartite_layout` expects the layer as a node attribute, so add the\n",
        "#         # numeric layer value as a node attribute\n",
        "#         for node in nodes:\n",
        "#             G.nodes[node][\"layer\"] = layer\n",
        "#     # Compute the multipartite_layout using the \"layer\" node attribute\n",
        "#     # pos = nx.multipartite_layout(G, subset_key=\"layer\")\n",
        "#     pos = nx.shell_layout(G) #, subset_key=\"layer\")\n",
        "#     fig, ax = plt.subplots()\n",
        "#     nx.draw_networkx(G, pos=pos, ax=ax)\n",
        "#     ax.set_title(\"DAG layout in topological order\")\n",
        "#     fig.tight_layout()\n",
        "#     plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "fca9392f-2ea9-4008-b134-d29430bd98dd",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269706
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# topological_plot(pred_graph)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "61debeba-767a-438c-a6af-8eed9393651f",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269738
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "bc7511b1-c320-4aeb-9c9d-79231edc91dd",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Adding domain-specific graph constraints\n",
        "To improve the quality of the learned graph, it is possible to place constraints on the graph that DECI learns. The constraints come in two flavours:\n",
        " - *negative constraints* mean a certain edge cannot exist in the graph,\n",
        " - *positive constraints* mean a certain edge must exist in the graph."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "4125614f-79c4-45e1-8bee-1d3e67742057",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Constraint matrix coding is described in the DECI docstrings\n",
        "# # The constraint matrix has the same shape as the adjacency matrix\n",
        "# # A `nan` value means no constraint\n",
        "# # A 0 value means a negative constraint\n",
        "# # A 1 value means a positive constraint\n",
        "\n",
        "# constraint_matrix = np.full((len(varname_to_index.keys()), len(varname_to_index.keys())), np.nan, dtype=np.float32)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "955507cb-4f89-4259-95ce-eceb48144570",
          "inputWidgets": {},
          "title": ""
        },
        "gather": {
          "logged": 1679319269767
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temporal: First, we add temporal constraints, future does not cause the past"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "a739d00f-3cba-4cec-ba6d-fcf0e3d6ae1f",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # temporal constraints\n",
        "# prev_idxes = [varname_to_index[var] for var in varname_to_index.keys() if var.startswith(\"prev1\")]\n",
        "# cur_idxes = [varname_to_index[var] for var in varname_to_index.keys() if not var.startswith(\"prev1\")]\n",
        "\n",
        "# for prev_idx in prev_idxes:\n",
        "#     constraint_matrix[cur_idxes, prev_idx] = 0."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "5d201537-740b-43bd-9e5b-9da32cb04644",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secondly, constraints on the outcomes not to be a cause for others"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "668aa7d3-5fa6-4e5d-a160-c5a9e595b960",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# outcome_factors = ['die', 'recover']\n",
        "# outcome_idxes = [varname_to_index[var] for var in outcome_factors]\n",
        "# nonoutcome_idxes = [varname_to_index[var] for var in varname_to_index.keys() if var not in outcome_factors]\n",
        "\n",
        "# for out_idx in outcome_idxes:\n",
        "#     constraint_matrix[out_idx, nonoutcome_idxes] = 0."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "7bbdbb7b-73fc-4a35-b97d-f59c68bbd40b",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constraint_matrix"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "6395136e-c28a-4154-bc3d-db4b5a46c20c",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_id_c = model_id + \"_c\"\n",
        "# model_c = DECI.create(model_id_c, save_dir=os.path.join(outputs_root, model_id_c), variables=variables, model_config_dict=model_config, device=device)\n",
        "# model_c.set_graph_constraint(constraint_matrix)\n",
        "# model_c.run_train(train_dataset, training_params)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "ad56cf2f-5dc1-4cee-8607-96407937e7dc",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_graph_c = model_c.networkx_graph()\n",
        "# pred_graph_c = nx.relabel_nodes(pred_graph_c, varindex_to_name)\n",
        "# topological_plot(pred_graph_c)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "5f3f5fc3-fbd2-48e9-8a62-f4423caf9458",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thirdly, we know severity is a cause for sevirity_next, infection_prev to infection_next, and drug to cum_drug"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "a025b58c-a211-4839-a6d1-f657b3ae6cd8",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constraint_matrix_c2 = constraint_matrix.copy()\n",
        "\n",
        "# constraint_matrix_c2[varname_to_index['severity'], varname_to_index['drug']]=1.0\n",
        "# constraint_matrix_c2[varname_to_index['prev1_severity'], varname_to_index['prev1_drug']]=1.0\n",
        "# constraint_matrix_c2[varname_to_index['drug'], varname_to_index['severity']]=0.0\n",
        "# constraint_matrix_c2[varname_to_index['prev1_drug'], varname_to_index['prev1_severity']]=0.0\n",
        "\n",
        "# constraint_matrix_c2[varname_to_index['prev1_severity'], varname_to_index['severity']]=1.0\n",
        "# constraint_matrix_c2[varname_to_index['prev1_infection'], varname_to_index['infection']]=1.0\n",
        "\n",
        "# constraint_matrix_c2[varname_to_index['prev1_drug'], varname_to_index['severity']]=1.0\n",
        "# constraint_matrix_c2[varname_to_index['prev1_cum_drug'], varname_to_index['severity']]=1.0\n",
        "\n",
        "# constraint_matrix_c2[varname_to_index['drug'], varname_to_index['cum_drug']]=1.0\n",
        "# constraint_matrix_c2[varname_to_index['cum_drug'], varname_to_index['drug']]=0.0\n",
        "\n",
        "# constraint_matrix_c2[varname_to_index['prev1_drug'], varname_to_index['prev1_cum_drug']]=1.0\n",
        "# constraint_matrix_c2[varname_to_index['prev1_cum_drug'], varname_to_index['prev1_drug']]=0.0\n",
        "\n",
        "# constraint_matrix_c2"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "c2efd059-dc59-4062-8f99-2fe0e79d1048",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_id_c2 = model_id + \"_c2\"\n",
        "# model_c2 = DECI.create(model_id_c2, save_dir=os.path.join(outputs_root, model_id_c2), variables=variables, model_config_dict=model_config, device=device)\n",
        "# model_c2.set_graph_constraint(constraint_matrix_c2)\n",
        "# model_c2.run_train(train_dataset, training_params)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "d9e558e1-0b12-422f-940d-e5d716fff7e7",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_graph_c2 = model_c2.networkx_graph()\n",
        "# pred_graph_c2 = nx.relabel_nodes(pred_graph_c2, varindex_to_name)\n",
        "# topological_plot(pred_graph_c2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "77a0c0b9-cfdb-4b36-aa96-0610e2f4f1b9",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "b1ad5ff6-5560-4b9c-9e58-b07b14ba1f1b",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "454d18c2-470c-4162-9a20-f25ad59d276a",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: SimSim -- simulation for scenario analysis\n",
        "DECI has also fitted an SCM that captures the functional relationship and error distribution of this dataset. We can estimate ATE and CATE using do-based sampling E\\[X_{today}|do(X_{yesterday},drug=dose)].\n",
        "\n",
        "## Treatment effect estimation -- Definitions\n",
        "\n",
        "Treatment effects describe how a target variable (such as outcome_die) changes in response to an intervention on some other variables.\n",
        " - **Average Treatment Effect (ATE)** gives the difference between giving the drug to every patient, and not giving the treatment to any of them. This summarizes the overall or average effectiveness of the drug.\n",
        " - **Conditional Average Treatment Effect (CATE)** gives the difference between giving and not giving the drug, *restricted to a certain conditions or subgroup of patients*. For example, we could investigate the average treatment effect effect of drug on sever or nonsever patients (e.g., severity_now < 30. vs. severity_now > 109),.\n",
        " - **Individual Treatment Effect (ITE)** is the different in outcome_die between giving and not giving the drug *for one specific patient*."
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "d6be8378-00c3-4a1e-9e7e-699ff658c6da",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# from scipy import stats\n",
        "\n",
        "# def is_out(row):\n",
        "#     return (row[\n",
        "#         \"die\"] > 0.9 or row[\n",
        "#         \"recover\"] > 0.9 or row[\n",
        "#         \"prev1_die\"] > 0.9 or row[\n",
        "#         \"prev1_recover\"] > 0.9)\n",
        "#     return False\n",
        "    \n",
        "# def get_drug(row, dose):\n",
        "#     # depends on: severity\n",
        "#     # treatment threshold for today\n",
        "#     tx_threshold = random.randint(10, 50)\n",
        "#     drug = dose if row['severity'] > tx_threshold else 0\n",
        "#     return drug\n",
        "\n",
        "# def get_next_day(model, prev_day, colnames, varname_to_index, drug_dose=None, sample_count=1):\n",
        "#     cat_vars=[5, 6, 12, 13] #die/recover\n",
        "\n",
        "#     intervention_idxs=[]\n",
        "#     intervention_values=[]\n",
        "\n",
        "#     vars = [col for col in colnames if col.startswith('prev1_')]\n",
        "    \n",
        "#     intervention_idxs += [varname_to_index[var] for var in vars]\n",
        "#     intervention_values += [prev_day[var[len(\"prev1_\"):]] for var in vars]\n",
        "\n",
        "#     ### Model-based ATE estimate\n",
        "#     next_day = model.sample(\n",
        "#         sample_count, intervention_idxs=np.array(intervention_idxs), \n",
        "#         intervention_values=np.array(intervention_values)\n",
        "#     ).cpu().numpy()\n",
        "#     next_day_agg = next_day.mean(axis=0)\n",
        "\n",
        "#     tx_threshold = random.randint(10, 50)\n",
        "#     if (drug_dose is not None) and (next_day_agg[0] > tx_threshold): #severity\n",
        "#         # drug dose\n",
        "#         intervention_idxs = [varname_to_index[\n",
        "#             \"severity\"], varname_to_index[\"drug\"]] + intervention_idxs\n",
        "#         intervention_values = [next_day_agg[0], drug_dose] + intervention_values\n",
        "\n",
        "#         next_day = model.sample(\n",
        "#                 sample_count, intervention_idxs=np.array(intervention_idxs), \n",
        "#                 intervention_values=np.array(intervention_values)\n",
        "#             ).cpu().numpy()\n",
        "\n",
        "#     next_day_agg = next_day.mean(axis=0)\n",
        "#     next_day_agg[cat_vars] = stats.mode(next_day[:,cat_vars], axis=0).mode[0]\n",
        "#     return next_day_agg # next_day.mean(axis=0)\n",
        "\n",
        "# def run_simsim(model, population, df_core, df_prev, varname_to_index, num_of_days, dose):\n",
        "#     # init\n",
        "#     df_none=df_core.copy()\n",
        "#     end_flags = [False] * population # dead or recovered\n",
        "\n",
        "#     # foreach day\n",
        "#     for k in range(1, num_of_days+1):\n",
        "#         np_simk=np.empty_like(df_prev)\n",
        "#         np_simk[:]=np.NaN\n",
        "\n",
        "#         # foreach patient\n",
        "#         for row_idx in range(np_simk.shape[0]):\n",
        "#             row = df_prev.iloc[row_idx,:]\n",
        "#             if end_flags[row_idx]:\n",
        "#                 continue\n",
        "#             elif is_out(row):\n",
        "#                 # dead or recovered\n",
        "#                 # print('P', str(row_idx), 'gone')\n",
        "#                 end_flags[row_idx] = True\n",
        "#                 continue\n",
        "\n",
        "#             next_day = get_next_day(model, row, colnames=df_prev.columns, varname_to_index=varname_to_index, drug_dose=dose, sample_count=50)\n",
        "#             # print(next_day)\n",
        "#             np_simk[row_idx,:]=next_day\n",
        "        \n",
        "#         df_prev=pd.DataFrame(np_simk, columns=df_prev.columns)\n",
        "#         # add day_number & patient_id\n",
        "#         df_dayk=df_prev.copy()\n",
        "#         # df_dayk.loc[:,df_prev.columns]=df_prev.loc[:,df_prev.columns].copy()\n",
        "#         df_dayk[\"day_number\"]= [k] * population\n",
        "#         df_dayk[\"patient_id\"]= df_core[\"patient_id\"].values\n",
        "\n",
        "#         # add to the db\n",
        "#         df_none=df_none.append(df_dayk[df_none.columns], ignore_index=True)\n",
        "#         alive = len(end_flags) - sum(end_flags)\n",
        "\n",
        "#         if alive == 0:\n",
        "#             break\n",
        "#         print(\"Day\", k, \"is done, alive: \", alive)\n",
        "#         if k%10 == 0:\n",
        "#             df_none.to_csv(os.path.join(experiment_dir_c, 'simsim_data',str(k)+'.csv'))# No drug\n",
        "#     return df_none"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "e090c0f5-bb79-49f4-a842-17cb3d5ce49d",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment_dir_c=os.path.join(outputs_root, model_id_c)\n",
        "# os.mkdir(os.path.join(experiment_dir_c, 'simsim_data'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "cce2d6ad-9475-456d-9a71-08b583df37ca",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# experiment_dir_c2=os.path.join(outputs_root, model_id_c2)\n",
        "# os.mkdir(os.path.join(experiment_dir_c2, 'simsim_data'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "1be581eb-64ed-4c85-927b-364d02c5d437",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Condition on a particular dose -- here dose=0.2; we do the same for all the dose candidate to find the optimal dose policy:"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "42e679d4-9c27-430c-9b22-249cf713e935",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# population=5000 #everyone\n",
        "# df_core = df_train[df_train.day_number==0].sample(population, random_state=42).copy() \n",
        "\n",
        "# #  setup\n",
        "# df_prev = df_core[df_train_cohort.columns] # sample instead\n",
        "# num_of_days=60\n",
        "# dose = 0.2\n",
        "\n",
        "# df02_c=run_simsim(model_c, population, df_core, df_prev, varname_to_index, num_of_days, dose)\n",
        "# df02_c.to_csv(os.path.join(experiment_dir_c, 'simsim_data', 'deci_constrainted_dose0.2_max60days' +'.csv'))\n",
        "\n",
        "# print(df02_c['die'].sum())\n",
        "# print(df02_c['recover'].sum())\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "ab8e9def-4205-4ea4-87d9-abeff77b57d4",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# population=5000 #everyone\n",
        "# df_core = df_train[df_train.day_number==0].sample(population, random_state=42).copy() \n",
        "\n",
        "# #  setup\n",
        "# df_prev = df_core[df_train_cohort.columns] # sample instead\n",
        "# num_of_days=60\n",
        "# dose = 0.2\n",
        "\n",
        "# df02_c2=run_simsim(model_c2, population, df_core, df_prev, varname_to_index, num_of_days, dose)\n",
        "# df02_c2.to_csv(os.path.join(experiment_dir_c2, 'simsim_data', 'deci_constrainted_dose0.2_max60days' +'.csv'))\n",
        "\n",
        "# print(df02_c2['die'].sum())\n",
        "# print(df02_c2['recover'].sum())\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "9d0fa855-fd66-4fd2-96dd-dde0f1cde161",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "df04c0e6-fe6a-4e07-ac0d-c1e2a230bf0a",
          "inputWidgets": {},
          "title": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "showTitle": false,
          "cellMetadata": {},
          "nuid": "f5d8ab81-258a-401e-abfa-e529f2084d79",
          "inputWidgets": {},
          "title": ""
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.9.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "causica",
      "language": "python",
      "display_name": "causica"
    },
    "kernel_info": {
      "name": "causica"
    },
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "DECI bogovirus - databricks",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 2,
        "mostRecentlyExecutedCommandWithImplicitDF": {
          "commandId": 953124281886489,
          "dataframes": [
            "_sqldf"
          ]
        }
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 953124281886484
    },
    "interpreter": {
      "hash": "2fd0a64ad648981ef4b0280c53775d4f8aeceb44a2f0562bd016e7298af01310"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}